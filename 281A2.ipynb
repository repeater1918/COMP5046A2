{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BHO-6NSgyEt_"
      },
      "source": [
        "## 01. Dependencies & Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dependencies for entire notebook\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "import torch\n",
        "import torch.autograd as autograd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from nltk import word_tokenize, pos_tag, download, word_tokenize, download, corpus\n",
        "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
        "import nltk\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models import FastText\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "import datetime\n",
        "from tabulate import tabulate\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import gensim.downloader as api\n",
        "\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "download('punkt')\n",
        "download('averaged_perceptron_tagger')\n",
        "download('wordnet')\n",
        "download('stopwords')\n",
        "\n",
        "stpwrds = corpus.stopwords.words('english')\n",
        "stemmer = PorterStemmer()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWg6AnxfjExG",
        "outputId": "b63c7a9e-cee3-475d-84a0-29ba2c68ab74"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare train, val and test datasets\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "train_doc_id = '1yKFzWzdYMrmEpCzp4H7I30pZgxuVgwdZ'\n",
        "val_doc_id = '1oDPDN2LVeaRJ4YPeEhOn5T6T9fEdRTvv'\n",
        "test_doc_id = '1Cdw2CZUV1IzHBMjy22GeqqYxmW1t9VXi'\n",
        "\n",
        "downloaded = drive.CreateFile({'id':train_doc_id}) \n",
        "downloaded.GetContentFile('train.csv') \n",
        "downloaded = drive.CreateFile({'id':val_doc_id})\n",
        "downloaded.GetContentFile('val.csv')\n",
        "downloaded = drive.CreateFile({'id':test_doc_id}) \n",
        "downloaded.GetContentFile('test_without_labels.csv')\n",
        "\n",
        "df_train = pd.read_csv(\"/content/train.csv\")\n",
        "df_val = pd.read_csv(\"/content/val.csv\")\n",
        "df_test = pd.read_csv(\"/content/test_without_labels.csv\")"
      ],
      "metadata": {
        "id": "q_hh7Noy6VIk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "IlDeEdrUXC8q",
        "outputId": "69f6f1f8-dd1c-4ed6-f62d-4e2af1a617e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     sents labels\n",
              "0      wow      O\n",
              "1      WTF      T\n",
              "2  wpe wpe    O O\n",
              "3   hahaha      O\n",
              "4      wtf      T"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ba9fcc4-e9ff-4db4-a55e-2d60f0b9a108\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sents</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wow</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>WTF</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>wpe wpe</td>\n",
              "      <td>O O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hahaha</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>wtf</td>\n",
              "      <td>T</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ba9fcc4-e9ff-4db4-a55e-2d60f0b9a108')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ba9fcc4-e9ff-4db4-a55e-2d60f0b9a108 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ba9fcc4-e9ff-4db4-a55e-2d60f0b9a108');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 02. Pre-processing\n",
        "1. Basic conversion to tokens"
      ],
      "metadata": {
        "id": "j_Dy70uRcH7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = [sent.lower().split(' ') for sent in df_train['sents'].tolist() if sent not in ['', ' ']]\n",
        "Y_train = [tags.split(' ') for tags in df_train['labels'].tolist() if tags not in ['', ' ']]\n",
        "\n",
        "X_val = [sent.lower().split(' ') for sent in df_val['sents'].tolist() if sent not in ['', ' ']]\n",
        "Y_val = [tags.split(' ') for tags in df_val['labels'].tolist() if tags not in ['', ' ']]\n",
        "\n",
        "X_test = [sent.lower().split(' ') for sent in df_test['sents'].tolist() if sent not in ['', ' ']]\n",
        "\n",
        "X_combine = X_train + X_val + X_test\n",
        "Y_combine = Y_train + Y_val"
      ],
      "metadata": {
        "id": "UL6Ape50cK94"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A. Input Embedding"
      ],
      "metadata": {
        "id": "giEGTUsPkZto"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Syntactic Textual Feature Embedding: **POS Tagging**"
      ],
      "metadata": {
        "id": "4Sx9RRnSk5ws"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# X_train_pos = \n",
        "def create_pos_tags(input_list):\n",
        "    pos = [pos_tag(sent) for sent in input_list]\n",
        "    pos = [[pos for _, pos in l] for l in pos]\n",
        "    return pos\n",
        "\n",
        "X_train_pos = create_pos_tags(X_train)\n",
        "X_val_pos = create_pos_tags(X_val)\n",
        "X_test_pos = create_pos_tags(X_test)\n",
        "\n",
        "print(X_train_pos[:6])\n",
        "print(X_train[:6])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASC2GggElLfg",
        "outputId": "14f440a6-d9c2-48b4-c2e7-1a9e1fa6435a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['NN'], ['NN'], ['NN', 'NN'], ['NN'], ['NN'], ['NN', 'NN', 'NNP', 'NN', 'NN', 'IN', 'CD', 'NN']]\n",
            "[['wow'], ['wtf'], ['wpe', 'wpe'], ['hahaha'], ['wtf'], ['i', 'cant', '[sepa]', 'play', '[sepa]', 'with', '4', 'trash']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Create POS tags\n",
        "pos_combine = X_train_pos + X_val_pos + X_test_pos\n",
        "tag_list = list(sorted(set([tag for sublist in pos_combine for tag in sublist])))\n",
        "tag_list.append('LS')\n",
        "tag_list = sorted(tag_list)\n",
        "pos_idx = {t:i for i,t in enumerate(tag_list)}\n",
        "pos_idx['NN']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbEICLjsgpur",
        "outputId": "53340252-af06-4e06-dbb8-d4c5b79fa0d3"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Associate POS tag idx to source dataset\n",
        "[[pos_idx[tag] for tag in doc] for doc in X_train_pos][:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYyTtOUElX29",
        "outputId": "3b332b97-750c-49a8-eaa8-696cbfb10ea0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[15], [15], [15, 15], [15], [15], [15, 15, 16, 15, 15, 9, 5, 15]]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert feature to one-hot encoded\n",
        "label_encoder = LabelEncoder()\n",
        "integer_encoded = label_encoder.fit_transform(tag_list)\n",
        "integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
        "onehot_encoder = OneHotEncoder(sparse=False)\n",
        "onehot_encoded = onehot_encoder.fit_transform(integer_encoded)"
      ],
      "metadata": {
        "id": "5JOK1E_JjC1x"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_one_hot_pos_encoding(tag):\n",
        "    \"\"\" returns pos tag as a one hot vector \"\"\"\n",
        "    idx = pos_idx[tag]\n",
        "    return onehot_encoded[idx]"
      ],
      "metadata": {
        "id": "beOB2qBAkSXk"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "get_one_hot_pos_encoding('LS')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RgZiUyLpDcJ",
        "outputId": "14df9c9c-1b71-4774-ef42-404383b1ec91"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "       0., 0., 0., 0., 0., 0., 0.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Semantic Textual Feature Embedding: **FastText Skip-Gram**"
      ],
      "metadata": {
        "id": "s9RS0POdk9bM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build FastText Skip-Gram Model\n",
        "fast_text_sg_plain = FastText(sentences=X_combine,\n",
        "                            size=100,\n",
        "                            window=5,\n",
        "                            min_count=5,\n",
        "                            workers=4,\n",
        "                            sg=1)"
      ],
      "metadata": {
        "id": "qthxlj1f89h1"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Domain Feature Embedding:"
      ],
      "metadata": {
        "id": "WXDYF25Vk9Oe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Build a list of Dota strategy guides, glossaries, blogs, and discussion forums\n",
        "# along with the html tag that has relevant data embedded\n",
        "\n",
        "urls = {\"https://www.pcinvasion.com/a-beginners-guide-to-dota-2-part-one-the-basics/2/\": 'p', \n",
        "        \"https://www.pcinvasion.com/a-beginners-guide-to-dota-2-part-one-the-basics/\": 'p',\n",
        "        \"https://www.pcgamesn.com/dota/dota-2-beginner-s-guide-everything-you-need-know\": 'p',\n",
        "        \"https://www.killping.com/blog/dota2-guide-tips-to-improve-gameplay/\": 'p',\n",
        "        \"https://dota2.fandom.com/wiki/Glossary\": [\"dd\", \"dt\"]}\n",
        "\n",
        "headers = {'User-Agent': \n",
        "           'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "\n",
        "# Step 2: Add to the list of URLS the in depth guide for each Dota hero\n",
        "url_hero_directory = \"https://dota2.fandom.com/wiki/Heroes\"\n",
        "response = requests.get(url_hero_directory, headers=headers)\n",
        "soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "url_heroes = [\"https://dota2.fandom.com/\" + a['href'] + '/Guide' for a in \n",
        "              soup.find('body').find_all(\"a\") \n",
        "              if a.find(\"img\", {'class': \"lazyload\"})]\n",
        "\n",
        "for url in url_heroes:\n",
        "    urls[url] = 'li'\n",
        "\n",
        "# Preview list of URLS\n",
        "dict(list(urls.items())[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Njg1eVvFRUj",
        "outputId": "aac7c79a-6017-4ee7-87bc-e1c8c15bcb2e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'https://dota2.fandom.com//wiki/Axe/Guide': 'li',\n",
              " 'https://dota2.fandom.com//wiki/Beastmaster/Guide': 'li',\n",
              " 'https://dota2.fandom.com//wiki/Brewmaster/Guide': 'li',\n",
              " 'https://dota2.fandom.com//wiki/Bristleback/Guide': 'li',\n",
              " 'https://dota2.fandom.com//wiki/Centaur_Warrunner/Guide': 'li',\n",
              " 'https://dota2.fandom.com/wiki/Glossary': ['dd', 'dt'],\n",
              " 'https://www.killping.com/blog/dota2-guide-tips-to-improve-gameplay/': 'p',\n",
              " 'https://www.pcgamesn.com/dota/dota-2-beginner-s-guide-everything-you-need-know': 'p',\n",
              " 'https://www.pcinvasion.com/a-beginners-guide-to-dota-2-part-one-the-basics/': 'p',\n",
              " 'https://www.pcinvasion.com/a-beginners-guide-to-dota-2-part-one-the-basics/2/': 'p'}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "try:\n",
        "    # Try preload saved corpus data \n",
        "\n",
        "    dota_corpus_id = '1w-PrA7yAvzj68Nn1BM6TKiUz4Ludpfk2'\n",
        "    downloaded = drive.CreateFile({'id':dota_corpus_id}) \n",
        "    downloaded.GetContentFile('corpus.pickle') \n",
        "    infile = open('corpus.pickle','rb')\n",
        "    dota_corpus = pickle.load(infile)\n",
        "    infile.close()\n",
        "\n",
        "except:\n",
        "    # Otherwise generate corpus from scratch\n",
        "\n",
        "    dota_corpus = []\n",
        "\n",
        "    # Loop through and retreive relevant data\n",
        "    for url, tag in urls.items():\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, \"html.parser\")\n",
        "        text = [para.get_text() for para in soup.find('body').find_all(tag)]\n",
        "        dota_corpus.append(text)\n",
        "\n",
        "    # Rough cleaning procedure for html tags\n",
        "    c1 = [[txt for txt in l if txt[:1] != '\\n'] for l in dota_corpus]\n",
        "    c2 = [[txt for txt in l if not txt[:1].isdigit()] for l in c1]"
      ],
      "metadata": {
        "id": "agDqbvba_Rzm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1 - Flatten Array + add words from train, val and test\n",
        "dota_corpus = [doc for sublist in dota_corpus for doc in sublist if doc != '']\n",
        "# Step 2 - convert to lower case\n",
        "dota_corpus = [sent.lower() for sent in dota_corpus]\n",
        "# Step 3 - tockenize sentences\n",
        "dota_corpus = [word_tokenize(sent) for sent in dota_corpus] + X_combine\n",
        "# Step 4 - remove digits\n",
        "dota_corpus = [[wrd for wrd in l if not wrd.isdigit()] for l in dota_corpus]\n",
        "# Step 5 - remove stop words\n",
        "dota_corpus = [[wrd for wrd in l if wrd not in stpwrds] for l in dota_corpus]\n",
        "# Step 6 - Stemming\n",
        "dota_corpus = [[stemmer.stem(wrd) for wrd in l ] for l in dota_corpus]\n",
        "# Step 7 - remove punctuation & symbols\n",
        "# dota_corpus = [[wrd for wrd in l if wrd not in string.punctuation] for l in dota_corpus]\n",
        "# cleaned corpus\n",
        "dota_corpus[:2]"
      ],
      "metadata": {
        "id": "RCLP7zLTxU1w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca7d4de-8aee-478c-d72e-b5dc3da67f24"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['stuff', 'mention', '?', 'tower', ',', 'rainforest', ',', 'roshan', '?'],\n",
              " ['tower', ',', 'jungl', ',', 'roshan', '.', 'tower', '–']]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build FastText Semantic basis Skip-Gram Model\n",
        "fast_text_dota_2v_model = FastText(sentences=dota_corpus,\n",
        "                            size=100,\n",
        "                            window=5,\n",
        "                            min_count=5,\n",
        "                            workers=4,\n",
        "                            sg=1)"
      ],
      "metadata": {
        "id": "rmZbQcIF22EF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load specialsied list for custom features\n",
        "d2h_doc_id = '1h3v3h4wEkUaWD6KW2ZwJ-EtTVzjxYAZ_'\n",
        "d2t_doc_id = '1R550xevyE4T2UD0P9nv1JkOXq9vCYckb'\n",
        "bw_doc_id = '1ek241QhWqXuQoa6BGBXHu91yKQg5lq3W'\n",
        "\n",
        "downloaded = drive.CreateFile({'id':d2h_doc_id}) \n",
        "downloaded.GetContentFile('d2_heroes.pickle') \n",
        "downloaded = drive.CreateFile({'id':d2t_doc_id})\n",
        "downloaded.GetContentFile('d2_terms.pickle')\n",
        "downloaded = drive.CreateFile({'id':bw_doc_id}) \n",
        "downloaded.GetContentFile('bad_wrds.pickle')\n",
        "\n",
        "infile = open('d2_heroes.pickle','rb')\n",
        "d2_heroes = pickle.load(infile) # list of dota heroes\n",
        "infile.close()\n",
        "infile = open('d2_terms.pickle','rb')\n",
        "d2_terms = pickle.load(infile) # dota terms and acronyms\n",
        "infile.close()\n",
        "infile = open('bad_wrds.pickle','rb')\n",
        "bad_wrds = pickle.load(infile) # warning explicit! - list of offensive words in gaming domain\n",
        "infile.close()\n",
        "\n",
        "# prepare\n",
        "d2_heroes = [hero.lower() for hero in d2_heroes]"
      ],
      "metadata": {
        "id": "6E4xYWHbWwkM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create helper function that builds customised features\n",
        "def extract_features(word):\n",
        "\n",
        "    is_pronoun = pos_tag([word])[0][1] in ['PRP', 'PRP$']\n",
        "    is_profane = word in bad_wrds\n",
        "    is_hero = word in d2_heroes\n",
        "    is_dota2_term = word in d2_terms\n",
        "\n",
        "    features = [int(is_pronoun), int(is_profane), int(is_hero), int(is_dota2_term)]\n",
        "\n",
        "    return np.array(features)\n"
      ],
      "metadata": {
        "id": "dHq6RaZOFaAj"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Concatenate Inputs & Build embeddings"
      ],
      "metadata": {
        "id": "BUBIxy5ERM0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Word statistics\n",
        "\n",
        "## Define universal function to generate word_to_ix objects with\n",
        "#  CRF, N to M and Attention compatability\n",
        "def get_word_statistics(all_docs, add_bos_eos=False):\n",
        "    \"\"\"\n",
        "    Take all docs and returns word index, word list and vocab size\n",
        "    for the purposes of building a memory efficient embedding lookup table\n",
        "    \"\"\"\n",
        "\n",
        "    word_set = set() \n",
        "    for doc in all_docs:\n",
        "        for word in doc:\n",
        "            word_set.add(word)\n",
        "\n",
        "    # Sort for safety to ensure order is preserved\n",
        "    word_list = list(word_set)\n",
        "    word_list.sort()\n",
        "\n",
        "    #  IF attention add BOE EOS indicators\n",
        "    word_index = {} if not add_bos_eos else {BOS:0, EOS:1}\n",
        "\n",
        "    # Create and return integer based lookup table\n",
        "    for i, word in enumerate(word_list, len(word_index)):\n",
        "        word_index[word] = i\n",
        "\n",
        "    vocab_size = len(word_list)\n",
        "\n",
        "    return word_index, word_list, vocab_size\n",
        "\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)"
      ],
      "metadata": {
        "id": "pNync60yrc8t"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_pos_ft_embedding_table(word_list, model_ft):\n",
        "\n",
        "    # Builds an embedding table from FT + POS tags\n",
        "\n",
        "    embedding_table = []\n",
        "\n",
        "    dim_size = model_ft.vector_size + onehot_encoded.shape[1]\n",
        "\n",
        "    for word in word_list:\n",
        "\n",
        "            # Case 1: word is not present in pre-trained model == out of vocab error\n",
        "            # apply associative array of zeros\n",
        "            if word not in model_ft:\n",
        "                ft_vector = np.zeros((model_ft.vector_size))\n",
        "                pos_vector = get_one_hot_pos_encoding(pos_tag([word])[0][1])\n",
        "                embedding = np.concatenate((ft_vector, pos_vector))\n",
        "                embedding_table.append(embedding)\n",
        "\n",
        "            else:\n",
        "                # get POS vector \n",
        "                pos_vector = get_one_hot_pos_encoding(pos_tag([word])[0][1])\n",
        "                # get fast text vector\n",
        "                ft_vector = model_ft.wv[word]\n",
        "                # concat\n",
        "                embedding = np.concatenate((ft_vector, pos_vector))\n",
        "                # append to embedding\n",
        "                embedding_table.append(embedding)\n",
        "\n",
        "    return np.array(embedding_table), dim_size"
      ],
      "metadata": {
        "id": "6GOS4FluBVfX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build domain specific input embedding - FastText + websites + custom features\n",
        "def build_custom_ft_embedding_table(word_list, model_ft):\n",
        "\n",
        "    # Builds an embedding table from FT + custom features\n",
        "\n",
        "    embedding_table = []\n",
        "\n",
        "    dim_size = model_ft.vector_size + 4\n",
        "\n",
        "    for word in word_list:\n",
        "\n",
        "            # Case 1: word is not present in pre-trained model == out of vocab error\n",
        "            # apply associative array of zeros\n",
        "            if word not in model_ft:\n",
        "                ft_vector = np.zeros((model_ft.vector_size))\n",
        "                custom_feats = extract_features(word)\n",
        "                embedding = np.concatenate((ft_vector, custom_feats))\n",
        "                embedding_table.append(embedding)\n",
        "\n",
        "            else:\n",
        "                # get POS vector \n",
        "                custom_feats = extract_features(word)\n",
        "                # get fast text vector\n",
        "                ft_vector = model_ft.wv[word]\n",
        "                # concat\n",
        "                embedding = np.concatenate((ft_vector, custom_feats))\n",
        "                # append to embedding\n",
        "                embedding_table.append(embedding)\n",
        "\n",
        "    return np.array(embedding_table), dim_size"
      ],
      "metadata": {
        "id": "Qpx89Q2OAYdQ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Universal Supporting Functions"
      ],
      "metadata": {
        "id": "YwrEmNW9FOco"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "START_TAG = '<START>'\n",
        "STOP_TAG = '<STOP>'\n",
        "\n",
        "BOS = '<BOS>'\n",
        "EOS = '<EOS>'\n",
        "\n",
        "## Define universal function to generate tag_to_ix objects with\n",
        "#  CRF compatability\n",
        "def get_tag_statistics(all_labels):\n",
        "    \"\"\" Takes all domain labels and generates a reference index list \"\"\"\n",
        "\n",
        "    tag_index = {'<START>':0, '<STOP>':1}\n",
        "\n",
        "    tags = set([doc for sublist in all_labels for doc in sublist])\n",
        "\n",
        "    for ix, tag in enumerate(tags, 2):\n",
        "        tag_index[tag] = ix\n",
        "    return tag_index\n",
        "\n",
        "## Define universal function to generate word_to_ix objects with\n",
        "#  CRF, N to M and Attention compatability\n",
        "def get_word_statistics(all_docs, add_bos_eos=False):\n",
        "    \"\"\"\n",
        "    Take all docs and returns word index, word list and vocab size\n",
        "    for the purposes of building a memory efficient embedding lookup table\n",
        "    \"\"\"\n",
        "\n",
        "    word_set = set() \n",
        "    for doc in all_docs:\n",
        "        for word in doc:\n",
        "            word_set.add(word)\n",
        "\n",
        "    # Sort for safety to ensure order is preserved\n",
        "    word_list = list(word_set)\n",
        "    word_list.sort()\n",
        "\n",
        "    #  IF attention add BOE EOS indicators\n",
        "    word_index = {} if not add_bos_eos else {BOS:0, EOS:1}\n",
        "\n",
        "    # Create and return integer based lookup table\n",
        "    for i, word in enumerate(word_list, len(word_index)):\n",
        "        word_index[word] = i\n",
        "\n",
        "    vocab_size = len(word_list)\n",
        "\n",
        "    return word_index, word_list, vocab_size\n",
        "\n",
        "## Define a universal helper function that will create and \n",
        "# embedding table for one or more models\n",
        "def build_embedding_table(word_list, model_a, model_b=None):\n",
        "    \"\"\" \n",
        "    Builds an embedding table from one or more models\n",
        "\n",
        "    If two models is supplied function will assume requirements is to concatenate\n",
        "    embeddings\n",
        "\n",
        "    If concatenating 2+ models call function recursively\n",
        "\n",
        "    return embedding table and resultant vector size\n",
        "    \"\"\"\n",
        "\n",
        "    embedding_table = []\n",
        "\n",
        "    dim_size = (model_a.vector_size + model_b.vector_size) if model_b else model_a.vector_size\n",
        "\n",
        "    # If model_b has been supplied - assume input concatenation for embeddings\n",
        "    for word in word_list:\n",
        "\n",
        "        # Case 1: word is not present in pre-trained model == out of vocab error\n",
        "        # apply associative array of zeros\n",
        "        if word not in model_a:\n",
        "            embedding_table.append(np.zeros((dim_size)))\n",
        "\n",
        "        # Case 2: word is present in pre-trained model concatenate arrays if model_b\n",
        "        # is supplied else just append model_a embeddings\n",
        "        else:\n",
        "            if model_b and word in model_b:\n",
        "                embedding = np.concatenate((model_a.wv[word], model_b.wv[word]))\n",
        "            elif model_b and word not in model_b:\n",
        "                embedding_table.append(np.zeros((dim_size)))\n",
        "                continue\n",
        "            else:\n",
        "                embedding = model_a.wv[word]\n",
        "\n",
        "            embedding_table.append(embedding)\n",
        "\n",
        "    return np.array(embedding_table), dim_size\n",
        "\n",
        "# Create universal helper function that will take a coporpus or labels and\n",
        "#  convert dataset to their relevant indexes\n",
        "def convert_to_idx(docs, idx_reference):\n",
        "    \"\"\" Converts a word or tag to its reference based on given idx reference \"\"\"\n",
        "\n",
        "    input_index_list = []\n",
        "\n",
        "    for sent in docs:\n",
        "        input_index_list.append([idx_reference[wrd] for wrd in sent])\n",
        "    return input_index_list\n",
        "\n",
        "# EOS and BOE tagger for attention based models\n",
        "def label_sentence_bos_eos(docs):\n",
        "    \"\"\" appends eos (<STOP>) and bos (<START>) labels to sentences \"\"\"\n",
        "    output = [[START_TAG] + s for s in docs]\n",
        "    output = [s + [STOP_TAG] for s in docs]\n",
        "    return output\n",
        "\n",
        "\n",
        "# Saves predictions in kaggle readable format\n",
        "def save_predictions_to_csv(predictions):\n",
        "    \"\"\" convenience function that converts prediction dict to csv \"\"\"\n",
        "\n",
        "    with open('281.csv', 'w', newline='') as csvfile:\n",
        "        fieldnames = ['ID', 'Predicted']\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
        "\n",
        "        writer.writeheader()\n",
        "        for key in predictions:\n",
        "            writer.writerow({'ID': key, 'Predicted': predictions[key]})\n",
        "\n",
        "# Generates test predictions in format ready for kaggle\n",
        "def make_test_preds(model, crf=False):\n",
        "    \"\"\" generates prediction dict for fwd functions \"\"\"\n",
        "    \n",
        "    predicted = {}\n",
        "    i = 0\n",
        "\n",
        "    if crf:\n",
        "        for idxs in test_input_index:\n",
        "            _, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "            for p in pred:\n",
        "                tag = index_2_tag[p]\n",
        "                predicted[i] = tag\n",
        "                i += 1\n",
        "\n",
        "    else:\n",
        "\n",
        "        for idxs in test_input_index:\n",
        "            input = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            pred = model(input)\n",
        "            pred = pred.argmax(dim=1).cpu()\n",
        "            for p in pred:\n",
        "                tag = index_2_tag[int(p)]\n",
        "                predicted[i] = tag\n",
        "                i += 1\n",
        "\n",
        "    return predicted\n",
        "\n",
        "# Save baseline model\n",
        "def save_pytorch_model(model, name):\n",
        "    torch.save(model, name + '.pt')"
      ],
      "metadata": {
        "id": "lDrE5-crRRPG"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate word, tag and vocabulary indexs and statistics\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])"
      ],
      "metadata": {
        "id": "Hs6JJ9XhPcKf"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Baseline Model"
      ],
      "metadata": {
        "id": "bfjuPfH5ilK2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: code used in this section adapted from:\n",
        "1. https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html \n",
        "2. COMP5046_Lab09\n",
        "3. Pytorch: ADVANCED: MAKING DYNAMIC DECISIONS AND THE BI-LSTM CRF"
      ],
      "metadata": {
        "id": "Ahi2VVabqCk8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate word, tag and vocabulary indexs and statistics\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])"
      ],
      "metadata": {
        "id": "l2qJ9U_Vy1LM"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# baseline_embedding_matrix, dim_size = build_embedding_table(word_list, fast_text_sg_plain)\n",
        "# baseline_embedding_matrix, dim_size = build_pos_ft_embedding_table(word_list, fast_text_sg_plain)\n",
        "custom_embedding_matrix, dim_size = build_custom_ft_embedding_table(word_list, fast_text_dota_2v_model)\n",
        "\n",
        "def argmax(vec):\n",
        "    # return the argmax as a python int\n",
        "    _, idx = torch.max(vec, 1)\n",
        "    return idx.item()\n",
        "\n",
        "\n",
        "# Compute log sum exp in a numerically stable way for the forward algorithm\n",
        "def log_sum_exp(vec):\n",
        "    max_score = vec[0, argmax(vec)]\n",
        "    max_score_broadcast = max_score.view(1, -1).expand(1, vec.size()[1])\n",
        "    return max_score + \\\n",
        "        torch.log(torch.sum(torch.exp(vec - max_score_broadcast)))\n",
        "\n",
        "class BiLSTM_CRF(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, embeddings):\n",
        "        super(BiLSTM_CRF, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(embeddings))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=1, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "        # Matrix of transition parameters.  Entry i,j is the score of\n",
        "        # transitioning *to* i *from* j.\n",
        "        self.transitions = nn.Parameter(\n",
        "            torch.randn(self.tagset_size, self.tagset_size))\n",
        "\n",
        "        # These two statements enforce the constraint that we never transfer\n",
        "        # to the start tag and we never transfer from the stop tag\n",
        "        self.transitions.data[tag_to_ix[START_TAG], :] = -10000\n",
        "        self.transitions.data[:, tag_to_ix[STOP_TAG]] = -10000\n",
        "\n",
        "        self.hidden = self.init_hidden()\n",
        "\n",
        "    def init_hidden(self):\n",
        "        return (torch.randn(2, 1, self.hidden_dim // 2).to(device),\n",
        "                torch.randn(2, 1, self.hidden_dim // 2).to(device))\n",
        "\n",
        "    def _forward_alg(self, feats):\n",
        "        # Do the forward algorithm to compute the partition function\n",
        "        init_alphas = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        # START_TAG has all of the score.\n",
        "        init_alphas[0][self.tag_to_ix[START_TAG]] = 0.\n",
        "\n",
        "        # Wrap in a variable so that we will get automatic backprop\n",
        "        forward_var = init_alphas\n",
        "\n",
        "        # Iterate through the sentence\n",
        "        for feat in feats:\n",
        "            alphas_t = []  # The forward tensors at this timestep\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # broadcast the emission score: it is the same regardless of\n",
        "                # the previous tag\n",
        "                emit_score = feat[next_tag].view(\n",
        "                    1, -1).expand(1, self.tagset_size)\n",
        "                # the ith entry of trans_score is the score of transitioning to\n",
        "                # next_tag from i\n",
        "                trans_score = self.transitions[next_tag].view(1, -1)\n",
        "                # The ith entry of next_tag_var is the value for the\n",
        "                # edge (i -> next_tag) before we do log-sum-exp\n",
        "                next_tag_var = forward_var + trans_score + emit_score\n",
        "                # The forward variable for this tag is log-sum-exp of all the\n",
        "                # scores.\n",
        "                alphas_t.append(log_sum_exp(next_tag_var).view(1))\n",
        "            forward_var = torch.cat(alphas_t).view(1, -1)\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        alpha = log_sum_exp(terminal_var)\n",
        "        return alpha\n",
        "\n",
        "    def _get_lstm_features(self, sentence):\n",
        "        self.hidden = self.init_hidden()\n",
        "        embeds = self.word_embeds(sentence).view(len(sentence), 1, -1)\n",
        "        lstm_out, self.hidden = self.lstm(embeds, self.hidden)\n",
        "        lstm_out = lstm_out.view(len(sentence), self.hidden_dim)\n",
        "        lstm_feats = self.hidden2tag(lstm_out)\n",
        "        return lstm_feats\n",
        "\n",
        "    def _score_sentence(self, feats, tags):\n",
        "        # Gives the score of a provided tag sequence\n",
        "        score = torch.zeros(1).to(device)\n",
        "        tags = torch.cat([torch.tensor([self.tag_to_ix[START_TAG]], dtype=torch.long).to(device), tags])\n",
        "        for i, feat in enumerate(feats):\n",
        "            score = score + \\\n",
        "                self.transitions[tags[i + 1], tags[i]] + feat[tags[i + 1]]\n",
        "        score = score + self.transitions[self.tag_to_ix[STOP_TAG], tags[-1]]\n",
        "        return score\n",
        "\n",
        "    def _viterbi_decode(self, feats):\n",
        "        backpointers = []\n",
        "\n",
        "        # Initialize the viterbi variables in log space\n",
        "        init_vvars = torch.full((1, self.tagset_size), -10000.).to(device)\n",
        "        init_vvars[0][self.tag_to_ix[START_TAG]] = 0\n",
        "\n",
        "        # forward_var at step i holds the viterbi variables for step i-1\n",
        "        forward_var = init_vvars\n",
        "        for feat in feats:\n",
        "            bptrs_t = []  # holds the backpointers for this step\n",
        "            viterbivars_t = []  # holds the viterbi variables for this step\n",
        "\n",
        "            for next_tag in range(self.tagset_size):\n",
        "                # next_tag_var[i] holds the viterbi variable for tag i at the\n",
        "                # previous step, plus the score of transitioning\n",
        "                # from tag i to next_tag.\n",
        "                # We don't include the emission scores here because the max\n",
        "                # does not depend on them (we add them in below)\n",
        "                next_tag_var = forward_var + self.transitions[next_tag]\n",
        "                best_tag_id = argmax(next_tag_var)\n",
        "                bptrs_t.append(best_tag_id)\n",
        "                viterbivars_t.append(next_tag_var[0][best_tag_id].view(1))\n",
        "            # Now add in the emission scores, and assign forward_var to the set\n",
        "            # of viterbi variables we just computed\n",
        "            forward_var = (torch.cat(viterbivars_t) + feat).view(1, -1)\n",
        "            backpointers.append(bptrs_t)\n",
        "\n",
        "        # Transition to STOP_TAG\n",
        "        terminal_var = forward_var + self.transitions[self.tag_to_ix[STOP_TAG]]\n",
        "        best_tag_id = argmax(terminal_var)\n",
        "        path_score = terminal_var[0][best_tag_id]\n",
        "\n",
        "        # Follow the back pointers to decode the best path.\n",
        "        best_path = [best_tag_id]\n",
        "        for bptrs_t in reversed(backpointers):\n",
        "            best_tag_id = bptrs_t[best_tag_id]\n",
        "            best_path.append(best_tag_id)\n",
        "        # Pop off the start tag (we dont want to return that to the caller)\n",
        "        start = best_path.pop()\n",
        "        assert start == self.tag_to_ix[START_TAG]  # Sanity check\n",
        "        best_path.reverse()\n",
        "        return path_score, best_path\n",
        "\n",
        "    def neg_log_likelihood(self, sentence, tags):\n",
        "        feats = self._get_lstm_features(sentence)\n",
        "        forward_score = self._forward_alg(feats)\n",
        "        gold_score = self._score_sentence(feats, tags)\n",
        "        return forward_score - gold_score\n",
        "\n",
        "    def forward(self, sentence):  # dont confuse this with _forward_alg above.\n",
        "        # Get the emission scores from the BiLSTM\n",
        "        lstm_feats = self._get_lstm_features(sentence)\n",
        "\n",
        "        # Find the best path, given the features.\n",
        "        score, tag_seq = self._viterbi_decode(lstm_feats)\n",
        "        return score, tag_seq\n",
        "\n",
        "HIDDEN_DIM = 50\n",
        "model_bi_ltsm_crf = BiLSTM_CRF(vocab_size, tag_index, dim_size, HIDDEN_DIM, custom_embedding_matrix).to(device)\n",
        "optimizer = optim.SGD(model_bi_ltsm_crf.parameters(), lr=0.1)"
      ],
      "metadata": {
        "id": "w50McPxJjETz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6e5bdcf2-2f8b-464b-e114-a69f1edc7732"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_accuracy_crf(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        _, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    f1 = f1_score(ground_truth, predicted, average='weighted')\n",
        "    return f1, accuracy"
      ],
      "metadata": {
        "id": "oCLXx9-NU9Pp"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_classes_crf(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        _, pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred\n",
        "    f1_classes = f1_score(ground_truth, predicted, average=None, labels=list(tag_index.values())[2:])\n",
        "    return f1_classes"
      ],
      "metadata": {
        "id": "-w2hrTFgCov4"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "def train_baseline(optimizer, model_bi_ltsm_crf):\n",
        "\n",
        "    for epoch in range(2):  \n",
        "        train_loss = 0\n",
        "\n",
        "        model_bi_ltsm_crf.train()\n",
        "        for i, idxs in enumerate(train_input_index): # use training data\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            model_bi_ltsm_crf.zero_grad()\n",
        "\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            loss = model_bi_ltsm_crf.neg_log_likelihood(sentence_in, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model_bi_ltsm_crf.eval()\n",
        "\n",
        "        train_f1, train_acc = calculate_f1_accuracy_crf(model_bi_ltsm_crf,train_input_index,train_output_index)\n",
        "        val_f1, val_acc = calculate_f1_accuracy_crf(model_bi_ltsm_crf,val_input_index,val_output_index)\n",
        "\n",
        "        print(f'Epoch: {epoch + 1}, train F1: {train_f1}, validation F1: {val_f1}')\n",
        "\n",
        "    baseline_f1 = calculate_f1_classes_crf(model_bi_ltsm_crf,val_input_index,val_output_index)\n",
        "\n",
        "    return val_f1, baseline_f1"
      ],
      "metadata": {
        "id": "PTIHqe8FT-G2"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## C. Model Design"
      ],
      "metadata": {
        "id": "fkBxXkDZityU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Stacked Seq2Seq: Bi_LTSM Multi Stacks"
      ],
      "metadata": {
        "id": "aSszZxqlemr9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: code used in this section adapted from:\n",
        "1. https://pytorch.org/tutorials/beginner/nlp/advanced_tutorial.html \n",
        "2. COMP5046_Lab09"
      ],
      "metadata": {
        "id": "D4wkAlzXqdx6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate word, tag and vocabulary indexs and statistics\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])"
      ],
      "metadata": {
        "id": "-XilQmThgQ1k"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_accuracy_non_crf(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred.argmax(dim=1).cpu()\n",
        "    accuracy = sum(np.array(ground_truth) == np.array(predicted))/len(ground_truth)\n",
        "    f1 = f1_score(ground_truth, predicted, average='weighted')\n",
        "    return f1, accuracy"
      ],
      "metadata": {
        "id": "NxfjSonxQNnx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_classes_non_crf(model, input_index, output_index):\n",
        "    ground_truth = []\n",
        "    predicted = []\n",
        "    for i,idxs in enumerate(input_index):\n",
        "        ground_truth += output_index[i]\n",
        "        pred = model(torch.tensor(idxs, dtype=torch.long).to(device))\n",
        "        predicted += pred.argmax(dim=1).cpu()\n",
        "    f1_classes = f1_score(ground_truth, predicted, average=None, labels=list(tag_index.values())[2:])\n",
        "    return f1_classes"
      ],
      "metadata": {
        "id": "6bKEnpkdTeu1"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "baseline_embedding_matrix, dim_size = build_embedding_table(word_list, fast_text_sg_plain)\n",
        "# baseline_embedding_matrix, dim_size = build_custom_ft_embedding_table(word_list, fast_text_dota_2v_model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class BiLSTM_Seq2Seq(nn.Module):\n",
        "\n",
        "    def __init__(self, vocab_size, tag_to_ix, embedding_dim, hidden_dim, embeddings, stacks=1):\n",
        "        super(BiLSTM_Seq2Seq, self).__init__()\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.vocab_size = vocab_size\n",
        "        self.tag_to_ix = tag_to_ix\n",
        "        self.tagset_size = len(tag_to_ix)\n",
        "\n",
        "        self.word_embeds = nn.Embedding(vocab_size, embedding_dim)\n",
        "\n",
        "        \"\"\"Here we use the embedding matrix as the initial weights of nn.Embedding\"\"\"\n",
        "        self.word_embeds.weight.data.copy_(torch.from_numpy(baseline_embedding_matrix))\n",
        "        \n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim // 2,\n",
        "                            num_layers=stacks, bidirectional=True)\n",
        "\n",
        "        # Maps the output of the LSTM into tag space.\n",
        "        self.hidden2tag = nn.Linear(hidden_dim, self.tagset_size)\n",
        "\n",
        "    def forward(self, sentence):\n",
        "        embeds = self.word_embeds(sentence)\n",
        "        lstm_out, _ = self.lstm(embeds.view(len(sentence), 1, -1))\n",
        "        tag_space = self.hidden2tag(lstm_out.view(len(sentence), -1))\n",
        "        tag_scores = F.log_softmax(tag_space, dim=1)\n",
        "        return tag_scores\n",
        "\n",
        "model_bi_ltsm_s2s = BiLSTM_Seq2Seq(vocab_size, tag_index, dim_size, 50, baseline_embedding_matrix, 1).to(device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model_bi_ltsm_s2s.parameters(), lr=0.1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrnWyHH4FVGc",
        "outputId": "d2860db3-0ec1-47c4-a32b-fc7e7fceb2f0"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_stacks(optimizer, model_bi_ltsm_s2s):\n",
        "\n",
        "    for epoch in range(2):  \n",
        "        time1 = datetime.datetime.now()\n",
        "        train_loss = 0\n",
        "\n",
        "        model_bi_ltsm_s2s.train()\n",
        "        for i, idxs in enumerate(train_input_index):\n",
        "            tags_index = train_output_index[i]\n",
        "\n",
        "            # Step 1. Remember that Pytorch accumulates gradients.\n",
        "            # We need to clear them out before each instance\n",
        "            model_bi_ltsm_s2s.zero_grad()\n",
        "\n",
        "            # Step 2. Get our inputs ready for the network, that is,\n",
        "            # turn them into Tensors of word indices.\n",
        "            sentence_in = torch.tensor(idxs, dtype=torch.long).to(device)\n",
        "            targets = torch.tensor(tags_index, dtype=torch.long).to(device)\n",
        "\n",
        "            # Step 3. Run our forward pass.\n",
        "            tag_scores = model_bi_ltsm_s2s(sentence_in).to(device)\n",
        "\n",
        "            # Step 4. Compute the loss, gradients, and update the parameters by\n",
        "            # calling optimizer.step()\n",
        "            loss = loss_function(tag_scores, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss+=loss.item()\n",
        "\n",
        "        model_bi_ltsm_s2s.eval()\n",
        "        train_f1, train_acc = calculate_f1_accuracy_non_crf(model_bi_ltsm_s2s,train_input_index,train_output_index)\n",
        "        val_f1, val_acc = calculate_f1_accuracy_non_crf(model_bi_ltsm_s2s,val_input_index,val_output_index)\n",
        "\n",
        "        print(f'Epoch: {epoch + 1}, train F1: {train_f1}, validation F1: {val_f1}')\n",
        "\n",
        "    baseline_f1 = calculate_f1_classes_non_crf(model_bi_ltsm_s2s,val_input_index,val_output_index)\n",
        "\n",
        "    return val_f1, baseline_f1"
      ],
      "metadata": {
        "id": "DqoyAuu6IYm_"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Attention"
      ],
      "metadata": {
        "id": "MPmfCJuditNb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reference: code used in this section adapted from:\n",
        "1. https://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html\n",
        "2. COMP5046_Lab10"
      ],
      "metadata": {
        "id": "eRcM0bbrqVfT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_token_list = X_train + X_val\n",
        "answer_token_list = Y_train + Y_val\n",
        "output_token_list = [[\"<BOS>\"] + s for s in answer_token_list]\n",
        "target_token_list = [s + [\"<EOS>\"] for s in answer_token_list]\n",
        "n_data = len(X_train)\n",
        "MAX_LENGTH = max([len(s) for s in input_token_list] + [len(s) for s in target_token_list])"
      ],
      "metadata": {
        "id": "SVNhlMo7WEst"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_to_ix = {\"<BOS>\": 0, \"<EOS>\":1}\n",
        "for sentence in input_token_list+output_token_list:\n",
        "    for word in sentence:\n",
        "        if word not in word_to_ix:\n",
        "            word_to_ix[word] = len(word_to_ix)\n",
        "word_list = list(word_to_ix.keys())"
      ],
      "metadata": {
        "id": "75x_R4t0Rv0M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "def to_index(data, to_ix):\n",
        "    input_index_list = []\n",
        "    for sent in data:\n",
        "        input_index_list.append([to_ix[w] for w in sent])\n",
        "    return input_index_list\n",
        "\n",
        "input_index = to_index(input_token_list, word_to_ix)\n",
        "output_index = to_index(output_token_list, word_to_ix)\n",
        "target_index = to_index(target_token_list, word_to_ix)"
      ],
      "metadata": {
        "id": "nz2T177DYxd7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "class EncoderRNN(nn.Module):\n",
        "    def __init__(self, hidden_size, embedding):\n",
        "        super(EncoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.lstm = nn.GRU(hidden_size, hidden_size)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "        output, hidden = self.lstm(embedded, hidden) \n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)    \n",
        "\n",
        "class AttnDecoderRNN(nn.Module):\n",
        "    ATTN_TYPE_DOT_PRODUCT = \"Dot Product\"\n",
        "    ATTN_TYPE_SCALE_DOT_PRODUCT = \"Scale Dot Product\" \n",
        "    ATTN_TYPE_COSINE = \"Cosine\" \n",
        "\n",
        "    def __init__(self, hidden_size, output_size, embedding, method, max_length=MAX_LENGTH):\n",
        "        super(AttnDecoderRNN, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.output_size = output_size\n",
        "        self.max_length = max_length\n",
        "        self.method= method\n",
        "\n",
        "        self.embedding = embedding\n",
        "        self.lstm = nn.GRU(self.hidden_size, self.hidden_size)\n",
        "        self.out = nn.Linear(self.hidden_size*2, self.output_size)\n",
        "\n",
        "\n",
        "    def cal_attention(self, hidden, encoder_hiddens, method = ATTN_TYPE_DOT_PRODUCT):\n",
        "        # Dot Product Attention\n",
        "        if method == AttnDecoderRNN.ATTN_TYPE_DOT_PRODUCT:\n",
        "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "        # Scaled Dot Product Attention\n",
        "        elif method == AttnDecoderRNN.ATTN_TYPE_SCALE_DOT_PRODUCT:\n",
        "            attn_weights = F.softmax(1/np.sqrt(self.hidden_size)*torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "        # Cosine\n",
        "        elif method == AttnDecoderRNN.ATTN_TYPE_COSINE:\n",
        "            cos = nn.CosineSimilarity(dim=2, eps=1e-6)\n",
        "            attn_weights = F.softmax(cos(encoder_hiddens.unsqueeze(0),hidden),dim=-1)\n",
        "            attn_weights = F.softmax(torch.bmm(hidden, encoder_hiddens.T.unsqueeze(0)),dim=-1)\n",
        "            attn_output = torch.bmm(attn_weights, encoder_hiddens.unsqueeze(0))\n",
        "            concat_output = torch.cat((attn_output[0], hidden[0]), 1)\n",
        "\n",
        "        return concat_output\n",
        "\n",
        "    def forward(self, input, hidden, encoder_hiddens):\n",
        "        embedded = self.embedding(input).view(1, 1, -1)\n",
        "\n",
        "        _, hidden = self.lstm(embedded, hidden)\n",
        "\n",
        "        concat_output = self.cal_attention(hidden, encoder_hiddens, self.method)\n",
        "\n",
        "        output = F.log_softmax(self.out(concat_output), dim=1)\n",
        "        return output, hidden\n",
        "\n",
        "    def initHidden(self):\n",
        "        return torch.zeros(1, 1, self.hidden_size, device=device)\n",
        "\n",
        "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
        "    encoder_hidden = encoder.initHidden()\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    input_length = input_tensor.size(0)\n",
        "    target_length = target_tensor.size(0)\n",
        "\n",
        "    encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "    loss = 0\n",
        "\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "        encoder_hiddens[i] = encoder_hidden[0, 0]\n",
        "\n",
        "    decoder_input = torch.tensor([[0]], device=device)\n",
        "\n",
        "    decoder_hidden = encoder_hidden\n",
        "\n",
        "    # Teacher forcing: Feed the target as the next input\n",
        "    for i in range(target_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
        "        loss += criterion(decoder_output, target_tensor[i])\n",
        "        decoder_input = target_tensor[i]  # Teacher forcing\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item() / target_length\n",
        "\n",
        "import time\n",
        "import math\n",
        "\n",
        "\n",
        "def asMinutes(s):\n",
        "    m = math.floor(s / 60)\n",
        "    s -= m * 60\n",
        "    return '%dm %ds' % (m, s)\n",
        "\n",
        "\n",
        "def timeSince(since, percent):\n",
        "    now = time.time()\n",
        "    s = now - since\n",
        "    es = s / (percent)\n",
        "    rs = es - s\n",
        "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))\n",
        "\n",
        "import random\n",
        "def trainIters(encoder, decoder, learning_rate=0.1):\n",
        "    start = time.time()\n",
        "    plot_losses = []\n",
        "    print_loss_total = 0  # Reset every print_every\n",
        "    plot_loss_total = 0  # Reset every plot_every\n",
        "\n",
        "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
        "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
        "    \n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(2):\n",
        "        \n",
        "        for ix, idxs in enumerate(input_index):\n",
        "            input_index_r = [[ind] for ind in input_index[ix]]\n",
        "            target_index_r = [[ind] for ind in target_index[ix]]\n",
        "            \n",
        "            input_tensor = torch.LongTensor(input_index_r).to(device)\n",
        "            target_tensor = torch.LongTensor(target_index_r).to(device)\n",
        "            loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
        "            print_loss_total += loss\n",
        "            plot_loss_total += loss\n",
        "\n",
        "        print(f'Epoch train: {epoch}, Loss: {plot_loss_total}')"
      ],
      "metadata": {
        "id": "J-25C8vfXICX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# |hidden_size = 50\n",
        "# embedding = nn.Embedding(len(word_to_ix), hidden_size)\n",
        "# encoder1 = EncoderRNN(hidden_size, embedding).to(device)\n",
        "# attn_decoder1 = AttnDecoderRNN(hidden_size, len(word_to_ix), embedding,\"Dot Product\").to(device)\n",
        "# trainIters(encoder1, attn_decoder1)"
      ],
      "metadata": {
        "id": "L_6vKW9nhVzx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(encoder, decoder, input_sent, max_length=MAX_LENGTH):\n",
        "    with torch.no_grad():\n",
        "        input_index = [word_to_ix[word] for word in input_sent]\n",
        "        input_tensor = torch.LongTensor([[ind] for ind in input_index]).to(device)\n",
        "\n",
        "        input_length = input_tensor.size()[0]\n",
        "        encoder_hidden = encoder.initHidden()\n",
        "\n",
        "        encoder_hiddens = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
        "\n",
        "        for ei in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
        "            encoder_hiddens[ei] += encoder_hidden[0, 0]\n",
        "\n",
        "        decoder_input = torch.tensor([[0]], device=device) \n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "\n",
        "        decoded_words = []\n",
        "\n",
        "        for di in range(input_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, encoder_hiddens)\n",
        "            topv, topi = decoder_output.data.topk(1)\n",
        "            if topi.item() == 1:\n",
        "                if di != input_length:\n",
        "                    decoded_words.append('O')\n",
        "                else:\n",
        "                    decoded_words.append('<EOS>')\n",
        "                    break\n",
        "            else:\n",
        "                decoded_words.append(word_list[topi.item()])\n",
        "\n",
        "            decoder_input = topi.squeeze().detach()\n",
        "\n",
        "        return decoded_words"
      ],
      "metadata": {
        "id": "i3wrT1C4ZyMb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_f1_att_crf(ground_truth, predicted):\n",
        "    f1 = f1_score(ground_truth, predicted, average='weighted')\n",
        "    return f1\n",
        "\n",
        "def calculate_f1_classes_att_crf(ground_truth, predicted):\n",
        "    f1_classes = f1_score(ground_truth, predicted, average=None, labels=list(tag_index.values())[2:])\n",
        "    return f1_classes"
      ],
      "metadata": {
        "id": "vSl-J5pSDIHb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_attention(encoder, decoder):\n",
        "    predictions = [evaluate(encoder, decoder, input, max_length=MAX_LENGTH) for input in X_val]\n",
        "    predictions = [[token for token in sublist if token !='<EOS>'] for sublist in predictions]\n",
        "    predictions = [tag_index[doc] for sublist in predictions for doc in sublist]\n",
        "    ground_truth = [[tag_index[token] for token in sublist] for sublist in Y_val]\n",
        "    ground_truth = [doc for sublist in ground_truth for doc in sublist]\n",
        "    f1 = calculate_f1_att_crf(ground_truth, predictions)\n",
        "    f1_classes = calculate_f1_classes_att_crf(ground_truth, predictions)\n",
        "    return f1, f1_classes"
      ],
      "metadata": {
        "id": "Lg9XcfMAzcr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. CRF Attachment"
      ],
      "metadata": {
        "id": "SpteSi3bi951"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Could not successfully implement as mentioned in report"
      ],
      "metadata": {
        "id": "EGd8iHikUShw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## E. Ablation Studies\n",
        "\n",
        "**NOTE**: First run *all* cells in the following sections before running code in this section (view table of contents in colab for best results):\n",
        "1. .01 Dependencies & Setup\n",
        "2. .02 Pre-processing\n",
        "3. A. Input Embedding\n",
        "4. B. Baseline Model\n",
        "5. C. Model Design"
      ],
      "metadata": {
        "id": "zXsNwcwhjrqj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 0. Input Embeddings"
      ],
      "metadata": {
        "id": "BRtA0G29HGBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate word, tag and vocabulary indexs and statistics\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])\n",
        "\n",
        "ft_embedding_matrix, ft_dim_size = build_embedding_table(word_list, fast_text_sg_plain)\n",
        "ft_pos_embedding_matrix, ft_pos_dim_size = build_pos_ft_embedding_table(word_list, fast_text_sg_plain)\n",
        "domain_embedding_matrix, domain_dim_size = build_custom_ft_embedding_table(word_list, fast_text_dota_2v_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOYSKOEsF0Jz",
        "outputId": "ac39c542-461a-45d3-c078-711a62136369"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:71: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:13: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  del sys.path[0]\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test FastText EMbedding\n",
        "HIDDEN_DIM = 50\n",
        "baseline_ft = BiLSTM_CRF(vocab_size, tag_index, ft_dim_size, HIDDEN_DIM, ft_embedding_matrix).to(device)\n",
        "optimizer = optim.SGD(baseline_ft.parameters(), lr=0.1)\n",
        "f1_ft, f1_class_ft = train_baseline(optimizer, baseline_ft)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KAlvnNMGLbF",
        "outputId": "f30d0c60-c8cd-4cfc-e58c-10b8cbf303b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9985813183353329, validation F1: 0.9950886016756344\n",
            "Epoch: 2, train F1: 0.9998493860107002, validation F1: 0.9956652084932874\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test FastText + POS EMbedding\n",
        "HIDDEN_DIM = 50\n",
        "baseline_ft_pos = BiLSTM_CRF(vocab_size, tag_index, ft_pos_dim_size, HIDDEN_DIM, ft_pos_embedding_matrix).to(device)\n",
        "optimizer = optim.SGD(baseline_ft_pos.parameters(), lr=0.1)\n",
        "f1_ft_pos, f1_class_ft_pos = train_baseline(optimizer, baseline_ft_pos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG-GVFfeGbss",
        "outputId": "8488a3f4-2fb1-4c7b-cf5f-f7d12b639657"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9985396195485442, validation F1: 0.9953262782721041\n",
            "Epoch: 2, train F1: 0.9997993051918642, validation F1: 0.9957256107591622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Test custom embeddings\n",
        "HIDDEN_DIM = 50\n",
        "baseline_domain = BiLSTM_CRF(vocab_size, tag_index, domain_dim_size, HIDDEN_DIM, domain_embedding_matrix).to(device)\n",
        "optimizer = optim.SGD(baseline_domain.parameters(), lr=0.1)\n",
        "f1_domain, f1_class_domain  = train_baseline(optimizer, baseline_domain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LMejz4BqGbg_",
        "outputId": "0c043fef-48e9-46ec-d844-881b01b7cf77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9990163573677321, validation F1: 0.9959790003483713\n",
            "Epoch: 2, train F1: 0.9999297357323451, validation F1: 0.9969927310695462\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['Model Variant', 'T-F1(C)', 'T-F1(D)', 'T-F1(O)', 'T-F1(P)', 'T-F1(S)', 'T-F1(T)', 'F1-Weighted']\n",
        "model_name = ['FastText (CONDA Corpus)', 'FastText (CONDA Corpus) + POS', 'Domain Specific Embeddings']\n",
        "all_res = [f1_class_ft, f1_class_ft_pos, f1_class_domain]\n",
        "results = [[f'{res[0]*100:.2f}%', f'{res[1]*100:.2f}%', f'{res[2]*100:.2f}%', \n",
        "             f'{res[3]*100:.2f}%', f'{res[4]*100:.2f}%', f'{res[6]*100:.2f}%'] for res in all_res]\n",
        "all_f1 = [f1_ft, f1_ft_pos, f1_domain]\n",
        "[res.append(f'{f1*100:.2f}%') for res, f1 in zip(results, all_f1)]\n",
        "\n",
        "table = [(model, res[0], res[1], res[2], res[3], res[4], res[5], res[6]) for model, res in zip(model_name, results)]\n",
        "\n",
        "print('\\n')\n",
        "print('Table 1 Metrics: Emmbedding performance on baseline Bi-LSTM CRF Model')\n",
        "print('\\n')\n",
        "print(tabulate(table, headers, tablefmt=\"github\"))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1pMzwSdNcgBz",
        "outputId": "d199a1b6-8279-457a-eee1-27136898def9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Table 1 Metrics: Emmbedding performance on baseline Bi-LSTM CRF Model\n",
            "\n",
            "\n",
            "| Model Variant                 | T-F1(C)   | T-F1(D)   | T-F1(O)   | T-F1(P)   | T-F1(S)   | T-F1(T)   | F1-Weighted   |\n",
            "|-------------------------------|-----------|-----------|-----------|-----------|-----------|-----------|---------------|\n",
            "| FastText (CONDA Corpus)       | 99.62%    | 99.89%    | 98.58%    | 98.07%    | 97.95%    | 100.00%   | 99.57%        |\n",
            "| FastText (CONDA Corpus) + POS | 99.65%    | 99.94%    | 98.64%    | 98.11%    | 97.95%    | 100.00%   | 99.57%        |\n",
            "| Domain Specific Embeddings    | 99.68%    | 99.94%    | 98.86%    | 99.11%    | 98.21%    | 100.00%   | 99.70%        |\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#save models\n",
        "save_pytorch_model(baseline_ft, 'baseline_ft')\n",
        "save_pytorch_model(baseline_ft_pos, 'baseline_ft_pos')\n",
        "save_pytorch_model(baseline_domain, 'BEST_MODEL_baseline_domain')"
      ],
      "metadata": {
        "id": "joZDZMnynnco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Different Attention Strategy"
      ],
      "metadata": {
        "id": "GtWfZfdWjuca"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note - All cells in Attention section in table of contents must be run before running below"
      ],
      "metadata": {
        "id": "LTtqVOHiALGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dot Product\n",
        "hidden_size = 50\n",
        "embedding = nn.Embedding(len(word_to_ix), hidden_size)\n",
        "encoder_dprod = EncoderRNN(hidden_size, embedding).to(device)\n",
        "attn_decoder_dprod = AttnDecoderRNN(hidden_size, len(word_to_ix), embedding,\"Dot Product\").to(device)\n",
        "trainIters(encoder_dprod, attn_decoder_dprod)\n",
        "f1_att_dprod, f1_class_att_dprod = evaluate_attention(encoder_dprod, attn_decoder_dprod)"
      ],
      "metadata": {
        "id": "AxmL_1j-kGep",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49ab570-2ae9-4ff2-b1c7-4b5e765101af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch train: 0, Loss: 319447.7608731874\n",
            "Epoch train: 1, Loss: 661008.0890895978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Scale Dot Product\n",
        "hidden_size = 50\n",
        "embedding = nn.Embedding(len(word_to_ix), hidden_size)\n",
        "encoder_sdp = EncoderRNN(hidden_size, embedding).to(device)\n",
        "attn_decoder_sdp = AttnDecoderRNN(hidden_size, len(word_to_ix), embedding,\"Scale Dot Product\").to(device)\n",
        "trainIters(encoder_sdp, attn_decoder_sdp)\n",
        "f1_att_sdp, f1_class_att_sdp = evaluate_attention(encoder_sdp, attn_decoder_sdp)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezcmBbp4CbnM",
        "outputId": "c72aca7c-b706-426d-fa40-e3a84d4568f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch train: 0, Loss: 183314.9353084668\n",
            "Epoch train: 1, Loss: 353773.96675233793\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cosine\n",
        "hidden_size = 50\n",
        "embedding = nn.Embedding(len(word_to_ix), hidden_size)\n",
        "encoder_cos = EncoderRNN(hidden_size, embedding).to(device)\n",
        "attn_decoder_cos = AttnDecoderRNN(hidden_size, len(word_to_ix), embedding,\"Cosine\").to(device)\n",
        "trainIters(encoder_cos, attn_decoder_cos)\n",
        "f1_att_cos, f1_class_att_cos = evaluate_attention(encoder_cos, attn_decoder_cos)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yx2WB5eIFflQ",
        "outputId": "b47c223e-33e5-4604-98d0-088864133df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch train: 0, Loss: 355756.92934421136\n",
            "Epoch train: 1, Loss: 645679.6649882921\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['Model Variant', 'T-F1(C)', 'T-F1(D)', 'T-F1(O)', 'T-F1(P)', 'T-F1(S)', 'T-F1(T)', 'F1-Weighted']\n",
        "model_name = ['Attention - Dot Product', 'Attention - Scaled Dot Product', 'Attention - Cosine']\n",
        "all_res = [f1_class_att_dprod, f1_class_att_sdp, f1_class_att_cos]\n",
        "results = [[f'{res[0]*100:.2f}%', f'{res[1]*100:.2f}%', f'{res[2]*100:.2f}%', \n",
        "             f'{res[3]*100:.2f}%', f'{res[4]*100:.2f}%', f'{res[6]*100:.2f}%'] for res in all_res]\n",
        "all_f1 = [f1_att_dprod, f1_att_sdp, f1_att_cos]\n",
        "[res.append(f'{f1*100:.2f}%') for res, f1 in zip(results, all_f1)]\n",
        "\n",
        "table = [(model, res[0], res[1], res[2], res[3], res[4], res[5], res[6]) for model, res in zip(model_name, results)]\n",
        "\n",
        "print('\\n')\n",
        "print('Table 3 Metrics: GRU Attention Based Scores')\n",
        "print('\\n')\n",
        "print(tabulate(table, headers, tablefmt=\"github\"))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvi4M6tnFoWD",
        "outputId": "d7bdb175-86cd-4095-948b-3e447fd2f395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Table 3 Metrics: GRU Attention Based Scores\n",
            "\n",
            "\n",
            "| Model Variant                  | T-F1(C)   | T-F1(D)   | T-F1(O)   | T-F1(P)   | T-F1(S)   | T-F1(T)   | F1-Weighted   |\n",
            "|--------------------------------|-----------|-----------|-----------|-----------|-----------|-----------|---------------|\n",
            "| Attention - Dot Product        | 38.90%    | 10.96%    | 10.38%    | 3.01%     | 1.36%     | 13.93%    | 44.14%        |\n",
            "| Attention - Scaled Dot Product | 35.82%    | 21.18%    | 1.36%     | 2.16%     | 0.00%     | 8.22%     | 38.34%        |\n",
            "| Attention - Cosine             | 33.68%    | 5.80%     | 5.95%     | 9.15%     | 0.00%     | 10.71%    | 42.63%        |\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save models\n",
        "save_pytorch_model(encoder_dprod, 'encoder_dprod')\n",
        "save_pytorch_model(attn_decoder_dprod, 'attn_decoder_dprod')\n",
        "save_pytorch_model(encoder_sdp, 'encoder_sdp')\n",
        "save_pytorch_model(attn_decoder_sdp, 'attn_decoder_sdp')\n",
        "# save_pytorch_model(encoder_cos, 'encoder_cos')\n",
        "# save_pytorch_model(attn_decoder_cos, 'attn_decoder_cos')"
      ],
      "metadata": {
        "id": "t7xWzE3Jn_bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Different Stacked layer"
      ],
      "metadata": {
        "id": "IRPu7phsjuUX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Note - Stacked Seq2Seq section in table of contents must be run before running below"
      ],
      "metadata": {
        "id": "W4r1l47_WLgi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1 layers LSTM\n",
        "model_bi_ltsm_s2s_1 = BiLSTM_Seq2Seq(vocab_size, tag_index, dim_size, 50, domain_embedding_matrix, 1).to(device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model_bi_ltsm_s2s_1.parameters(), lr=0.1)\n",
        "f1_s1, f1_class_s1  = train_stacks(optimizer, model_bi_ltsm_s2s_1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Fm7qCK3vVTo",
        "outputId": "25f83416-52aa-424a-ef19-936631b91cb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9962362394263239, validation F1: 0.9934645308777651\n",
            "Epoch: 2, train F1: 0.99910722508622, validation F1: 0.9950956929487292\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2 layers LSTM\n",
        "model_bi_ltsm_s2s_2 = BiLSTM_Seq2Seq(vocab_size, tag_index, dim_size, 50, domain_embedding_matrix, 2).to(device)\n",
        "loss_function = nn.NLLLoss()\n",
        "optimizer = optim.SGD(model_bi_ltsm_s2s_2.parameters(), lr=0.1)\n",
        "f1_s2, f1_class_s2  = train_stacks(optimizer, model_bi_ltsm_s2s_2)"
      ],
      "metadata": {
        "id": "Uj1M9PxgkHEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "99280048-8885-4f64-b040-cb83ed3ccbd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9945056230519578, validation F1: 0.9916305304132739\n",
            "Epoch: 2, train F1: 0.9983135606993488, validation F1: 0.9941024199688637\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['Model Variant', 'T-F1(C)', 'T-F1(D)', 'T-F1(O)', 'T-F1(P)', 'T-F1(S)', 'T-F1(T)', 'F1-Weighted']\n",
        "model_name = ['Bi-LSTM - 1 Stack', 'Bi-LSTM - 2 Stack']\n",
        "all_res = [f1_class_s1, f1_class_s2]\n",
        "results = [[f'{res[0]*100:.2f}%', f'{res[1]*100:.2f}%', f'{res[2]*100:.2f}%', \n",
        "             f'{res[3]*100:.2f}%', f'{res[4]*100:.2f}%', f'{res[6]*100:.2f}%'] for res in all_res]\n",
        "all_f1 = [f1_s1, f1_s2]\n",
        "[res.append(f'{f1*100:.2f}%') for res, f1 in zip(results, all_f1)]\n",
        "\n",
        "table = [(model, res[0], res[1], res[2], res[3], res[4], res[5], res[6]) for model, res in zip(model_name, results)]\n",
        "\n",
        "print('\\n')\n",
        "print('Table 2 Metrics: Stacked Bi-LSTM Models')\n",
        "print('\\n')\n",
        "print(tabulate(table, headers, tablefmt=\"github\"))\n",
        "print('\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "49Gmm-hBFpQ0",
        "outputId": "99fcea89-7832-42d8-d0a2-4ef1bcb0843f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Table 2 Metrics: Stacked Bi-LSTM Models\n",
            "\n",
            "\n",
            "| Model Variant     | T-F1(C)   | T-F1(D)   | T-F1(O)   | T-F1(P)   | T-F1(S)   | T-F1(T)   | F1-Weighted   |\n",
            "|-------------------|-----------|-----------|-----------|-----------|-----------|-----------|---------------|\n",
            "| Bi-LSTM - 1 Stack | 99.59%    | 99.86%    | 98.37%    | 98.00%    | 97.34%    | 100.00%   | 99.51%        |\n",
            "| Bi-LSTM - 2 Stack | 99.53%    | 99.75%    | 97.94%    | 97.64%    | 95.23%    | 100.00%   | 99.41%        |\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save models\n",
        "save_pytorch_model(model_bi_ltsm_s2s_1, 'model_bi_ltsm_s2s_1')\n",
        "save_pytorch_model(model_bi_ltsm_s2s_2, 'model_bi_ltsm_s2s_2')"
      ],
      "metadata": {
        "id": "r1UJmVg7njW1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. With/without CRF "
      ],
      "metadata": {
        "id": "GD1qMmgajuKz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "headers = ['Model Variant', 'T-F1(C)', 'T-F1(D)', 'T-F1(O)', 'T-F1(P)', 'T-F1(S)', 'T-F1(T)', 'F1-Weighted']\n",
        "model_name = ['Without CRF - Attention - Dot Product', 'With CRF - Attention - Dot Product']\n",
        "all_res = [f1_class_att_dprod, [0,0,0,0,0,0,0]]\n",
        "results = [[f'{res[0]*100:.2f}%', f'{res[1]*100:.2f}%', f'{res[2]*100:.2f}%', \n",
        "             f'{res[3]*100:.2f}%', f'{res[4]*100:.2f}%', f'{res[6]*100:.2f}%'] for res in all_res]\n",
        "all_f1 = [f1_att_dprod, 'error']\n",
        "[res.append(f1) for res, f1 in zip(results, all_f1)]\n",
        "\n",
        "table = [(model, res[0], res[1], res[2], res[3], res[4], res[5], res[6]) for model, res in zip(model_name, results)]\n",
        "\n",
        "print('\\n')\n",
        "print('Table 4 Metrics: With CRF Attachment')\n",
        "print('\\n')\n",
        "print(tabulate(table, headers, tablefmt=\"github\"))\n",
        "print('\\n')"
      ],
      "metadata": {
        "id": "yYkr5awmjtiW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa778d6a-f77e-495e-e78e-57a00feb475a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Table 4 Metrics: With CRF Attachment\n",
            "\n",
            "\n",
            "| Model Variant                         | T-F1(C)   | T-F1(D)   | T-F1(O)   | T-F1(P)   | T-F1(S)   | T-F1(T)   | F1-Weighted         |\n",
            "|---------------------------------------|-----------|-----------|-----------|-----------|-----------|-----------|---------------------|\n",
            "| Without CRF - Attention - Dot Product | 38.90%    | 10.96%    | 10.38%    | 3.01%     | 1.36%     | 13.93%    | 0.44143093999186306 |\n",
            "| With CRF - Attention - Dot Product    | 0.00%     | 0.00%     | 0.00%     | 0.00%     | 0.00%     | 0.00%     | error               |\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## F. Kaggle Leaderboard Submission Format / Best Model\n",
        "\n",
        "**NOTE**: First run *all* cells in the following sections before running code in this section (view table of contents in colab for best results):\n",
        "1. .01 Dependencies & Setup\n",
        "2. .02 Pre-processing\n",
        "3. A. Input Embedding\n",
        "4. B. Baseline Model"
      ],
      "metadata": {
        "id": "x-kzXx38kKOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Replication of Best Model: Due to stachastic optimisation outputs may vary to results in Kaggle"
      ],
      "metadata": {
        "id": "GE-jgrKDoHIx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Model\n",
        "# Generate word, tag and vocabulary indexs and statistics\n",
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])\n",
        "\n",
        "# Embedding Matrix\n",
        "domain_embedding_matrix, domain_dim_size = build_custom_ft_embedding_table(word_list, fast_text_dota_2v_model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Train for 2 epoch\n",
        "HIDDEN_DIM = 50\n",
        "BEST_MODEL_baseline_domain = BiLSTM_CRF(vocab_size, tag_index, domain_dim_size, HIDDEN_DIM, domain_embedding_matrix).to(device)\n",
        "optimizer = optim.SGD(BEST_MODEL_baseline_domain.parameters(), lr=0.1)\n",
        "f1_domain, f1_class_domain  = train_baseline(optimizer, BEST_MODEL_baseline_domain)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B7hGpjyci0mG",
        "outputId": "cbe77926-3b5f-4c7b-984f-97533d6dc376"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1, train F1: 0.9989868782670633, validation F1: 0.9959436309835752\n",
            "Epoch: 2, train F1: 0.999899607376557, validation F1: 0.9967251948316809\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using trained model save model and generate test set predictions\n",
        "save_pytorch_model(BEST_MODEL_baseline_domain, 'BEST_MODEL_baseline_domain')\n",
        "save_predictions_to_csv(make_test_preds(BEST_MODEL_baseline_domain, True)) # saves predictions to 281.csv"
      ],
      "metadata": {
        "id": "r1joNOmCvFab"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load model\n",
        "# For some reason saving and loading model generates very different results. Have tried loading state dict and full model\n",
        "# suggest training model to validate kaggle score instead (see above)"
      ],
      "metadata": {
        "id": "SwwZhrfLrwwb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_index, word_list, vocab_size = get_word_statistics(X_combine)\n",
        "tag_index = get_tag_statistics(Y_combine)\n",
        "\n",
        "train_input_index =  convert_to_idx(X_train, word_index)\n",
        "train_output_index = convert_to_idx(Y_train, tag_index)\n",
        "val_input_index = convert_to_idx(X_val, word_index)\n",
        "val_output_index = convert_to_idx(Y_val, tag_index)\n",
        "test_input_index = convert_to_idx(X_test ,word_index)\n",
        "\n",
        "index_2_tag = dict([(value, key) for key, value in tag_index.items()])\n",
        "\n",
        "domain_embedding_matrix, domain_dim_size = build_custom_ft_embedding_table(word_list, fast_text_dota_2v_model)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model_id = '1n6BlmP3zzOA6VE0SAlt7yX7f8T32VTOM'\n",
        "downloaded = drive.CreateFile({'id':model_id}) \n",
        "downloaded.GetContentFile('best_model.pt')\n",
        "model = BiLSTM_CRF(vocab_size, tag_index, domain_dim_size, HIDDEN_DIM, domain_embedding_matrix).to(device)\n",
        "model.load_state_dict(torch.load(\"best_model.pt\"))\n",
        "model.train(False)\n",
        "make_test_preds(model, True)\n",
        "save_predictions_to_csv(make_test_preds(model, True)) # saves predictions to 281.csv"
      ],
      "metadata": {
        "id": "d12TGdeckWGn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1ae4bb4-9c9c-44f0-d22f-aa1eaeff5d1c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
            "  \n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cdff5599f505b215a85d3d0175a1841afbd020797d7c101a302ad0f34037af16"
    },
    "kernelspec": {
      "display_name": "Python 3.10.1 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "281A2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}